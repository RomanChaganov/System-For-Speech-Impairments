<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <title>О проекте</title>
    <link type="text/css" href="{{ url_for('static', filename='css/style.css') }}" rel="stylesheet">
    <link rel="icon" href="{{ url_for('static', filename='favicon.ico') }}">
</head>
<body>
    <div id="wrapper">
        <div id="header">
            <h1>Структура проекта</h1>
            <nav>
                <ul>
                 <li><a href="/">Главная</a></li>
                 <li><a href="/about">О нас</a></li>
                 <li style="border-right: 0;"><a href="/project">О проекте</a></li>
                </ul>
            </nav>
        </div>
        <div id="main">
            <h2>Нейронная сеть приходит на помощь</h2>
            <p>
                Наша команда пыталась ответить на вопрос: можно ли создать систему автоматического
                распознавания речи для людей, имеющих определенные дефекты в голосе (например, заикания).
                Чтобы сделать это, мы провели ряд процедур.
            </p>
            <p>
                Сначала мы создали набор данных. Наша команда работала со студентом магистратуры
                ИРИТ-РТФ Борисом Бредихиным, он имеет некоторые проблемы с речью. Мы записали ему фразы,
                он их озвучил. В прошлом семестре записали с ним 1000 фраз (около часа речи), а в этом записали еще
                1000. Датасет состоит теперь из 2000 фраз (2.33 часа речи).
            </p>
            <p>
                Далее мы рассмотрели текущие системы распознавания речи. Относительно недавно самыми
                распространенными были системы, построенные на основе Скрытых Мартовских моделей. HMM/GMM
                - это модели, основанные на классических методах обучения, они зачастую извлекали из речи
                фонемы, что требовало дополнительного преобразования в обычный текст. Таким образом, модели
                HMM/GMM показались нам слишком сложными и трудными в обучении.
            </p>
            <p>
                Тогда мы обратили свой взгляд на модели глубокого обучения. В этой области уже давно
                шествует метод обучения CTC (Connectionist Temporal Classification), этот метод позволяет не
                выравнивать входные и выходные данные, что упрощает обучение. В прошлом семестре мы решили
                взять готовую нейросеть и обучить её по методу CTC. Наиболее продвинутой нейронной сетью для
                распознавания речи на данный момент является Wav2Vec 2, и мы использовали её. Но такой вариант
                оказался ошибочным, ведь такие сети имеют несколько сотен миллионов параметров и обучать
                с нуля на нашем маленьком датасете ни к чему хорошему не приведет.
            </p>
            <p>
                Стало ясно, что нужно попробовать написать свою модель нейронной сети. В качестве фреймворка
                наша команда использовала Pytorch, он как раз имел в своём составе CTCLoss, функцию, которая
                очень важна нам. Но в отличие от Wav2Vec 2, которая на вход принимает просто массив байт из
                звукового файла, нами было принято решение, преобразовывать аудио в коэффициенты MFCC. Такой
                подход облегчил архитектуру сети. В итоге у нас получилась нейросеть, состоящая из сверточных и
                рекуррентных слоев. Одна из самых лучших моделей состоит всего из 2.6 миллионов параметров.
                Что касается метрик, то нам удалось достичь CER = 0.18 и WER = 0.73 .
            </p>
        </div>
        <div id="footer">
            <p>&copy; 2023 Gang Bros</p>
        </div>
    </div>
</body>
</html>